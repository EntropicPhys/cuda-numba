{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4 - Map-Reduce en CUDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMch++8v41BYxzXKFRmWqLT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguelamda/cuda-numba/blob/master/4_Map_Reduce_en_CUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mclcKM7IyiAd",
        "colab_type": "text"
      },
      "source": [
        "# IV. Map-Reduce En CUDA\n",
        "\n",
        "En programación funcional, las funciones de orden superior `map` y `reduce` son muy conocidas. Dada su potencia, se emplean de forma común en operaciones de tratamiento de datos en Big Data. Otra ventaja de estas operaciones es que son fácilmente paralelizables. Esto no es una excepción en las GPUs. Recuerda que estos dispositivos permiten escalar mejor la capacidad computacional en entornos distribuídos, ya que las tarjetas gráficas proveen a cada nodo con otro nivel más de paralelismo masivo.\n",
        "\n",
        "En concreto, `map` y `reduce` son conocidas como primitivas paralelas de la GPU. Hay otras primitivas paralelas para la GPU, pero no las cubriremos en este curso: `prefix sum`, `histogram`, `stencil`, `binning`, etc.\n",
        "\n",
        "Adentrémonos un poco en el mundo de la **algorítmica paralela**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfQ3CH3zNfLP",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Map\n",
        "\n",
        "Map es una función de orden superior. Esto se puede entender como que es una operación que recibe por parámetro otra función *unaria*, $f$. Después, aplica esa función a cada elemento de una colección. \n",
        "\n",
        "![seqmap](https://upload.wikimedia.org/wikipedia/commons/0/06/Mapping-steps-loillibe-new.gif)\n",
        "\n",
        "Hablemos un poco del *orden de complejidad* de la operación `map`. Usaremos para ello la notacion $O$, que nos indica cómo escala el tiempo de ejecución con respecto al tamaño de la entrada. En concreto, la operación `map` es $O(n)$. Esto significa que el tiempo de ejecutar la operación es proporcional al tamaño de la entrada, $n$. Piénsalo bien, tenemos que hacer un bucle para recorrer todos los elementos, y si tardaramos $m$ mili-segundos en aplicar la función $f$ a un elemento, entonces tardaríamos $m\\cdot n$ mili-segundos. \n",
        "\n",
        "Sin embargo, si somos capaces de aplicar cada evaluación de $f$ totalmente en paralelo, el orden de complejidad sería $O(1)$, es decir, constante. En otras palabras, da igual la entrada que tengamos, siempre va a tardar $m$ mili-segundos (independientemente de $n$, da igual $n$ sea 100 o 1.000.000 elementos). Sin embargo, en computación paralela también hay que lidiar con la limitación de recursos, por lo que es difícil tener todos los procesadores necesarios para alcanzar ese nivel de paralelismo. Si una GPU contiene $p$ procesadores, está claro que la carga se distribuye pero aún así tardaríamos $\\frac{n}{p}\\cdot m$ mili-segundos (asumiendo $n \\geq p$). Es decir, tendríamos un orden de complejidad $O(\\frac{n}{p})$. Aún así, ya es un resultado mucho mejor comparado con tal solo tener un procesador, y es que recuerda, una GPU puede contener hasta 3000 núcleos (a día de hoy).\n",
        "\n",
        "![parallelmap](https://github.com/miguelamda/cuda-numba/raw/master/img/parallelmap.png)\n",
        "\n",
        "En cierto modo, ya hemos visto como se puede implementar la operación `map` con Numba, y es a través de **ufunc**. Recuerda, estas operaciones se definen a nivel de elemento, y Python automáticamente escala la operación a todos los elementos de un array de Numpy.\n",
        "\n",
        "Veamos un ejemplo como el de la figura anterior, donde se suma un escalar a todos los elementos de un array:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0hKlx7avNHa",
        "colab_type": "code",
        "outputId": "3d35e510-409c-4f28-e97d-1c8b88f34a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from numba import vectorize\n",
        "import numpy as np\n",
        "\n",
        "# El vector de entrada como en el ejemplo anterior\n",
        "x = np.array([0, 5, 8, 3, 2, 1]).astype(np.int32)\n",
        "\n",
        "# Definamos la función f unaria como el ejemplo anterior \n",
        "@vectorize(['int32(int32)'], target='cuda')\n",
        "def f(x):\n",
        "    return x + 1\n",
        "\n",
        "# Automáticamente, Numpy aplica la función mediante broadcast, y Numba lo\n",
        "# paraleliza en la GPU\n",
        "xp = f(x)\n",
        "\n",
        "xp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 6, 9, 4, 3, 2], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBtIE1mZwL8S",
        "colab_type": "text"
      },
      "source": [
        "Aprovechando el sistema de broadcasting de Python, podemos aplicar parametrizar la función suma con una constante *n*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9QNpK1wwKzv",
        "colab_type": "code",
        "outputId": "52540645-0163-4428-e615-6c9f516c67ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Constante a ser configurada para la función.\n",
        "\n",
        "# Definamos una función f binaria, pero cuyo segundo parámetro será usado para n\n",
        "@vectorize(['int32(int32,int32)'], target='cuda')\n",
        "def fp(x,n):\n",
        "    return x + n\n",
        "\n",
        "xp2 = fp(xp,10)\n",
        "\n",
        "xp2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11, 16, 19, 14, 13, 12], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT9EH6l0wsj1",
        "colab_type": "text"
      },
      "source": [
        "Esta solución que hemos presentado sería ineficiente. Habría sido mejor hacer uso de arrays en memoria de GPU de forma explícita, para evitar copiar el vector xp al host, y de nuevo volverlo a enviar a device. Vamos a hacer una prueba con un array mucho más grande."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2ZCjkOQu81L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vamos a crear unos datos más grandes\n",
        "n = 500000000\n",
        "x = np.arange(n).astype(np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtuI2g7hyGlM",
        "colab_type": "text"
      },
      "source": [
        "El código siguiente demuestra la típica estructura de un código CUDA eficiente en el tratamiento de los datos. Esto ya lo vimos en el notebook anterior, pero conviene recordarlo:\n",
        "1. Copiar los datos a la GPU (device): `cuda.to_device()`\n",
        "2. Reservar toda la memoria auxiliar en la GPU: `cuda.device_array`\n",
        "3. Lanzar código GPU (ufunc o kernel): `@vectorize` o `@cuda.jit`\n",
        "4. Recuperar los resultados hacia la CPU (host): `cuda.copy_to_host()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzwYvIYgwxG9",
        "colab_type": "code",
        "outputId": "868fec85-4414-46bc-8135-8f31002907de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "from numba import cuda\n",
        "\n",
        "# 1. Copiar entrada a la GPU\n",
        "x_device = cuda.to_device(x)\n",
        "\n",
        "# 2. Inicializar los arrays auxiliares\n",
        "xp_device = cuda.device_array(shape=x_device.shape, dtype=x_device.dtype)\n",
        "xp2_device = cuda.device_array(shape=x_device.shape, dtype=x_device.dtype)\n",
        "\n",
        "# 3. Lanzamos las funciones map\n",
        "f(x_device, out=xp_device)\n",
        "fp(xp_device, -1, out=xp2_device)\n",
        "\n",
        "# 4. Copiamos el resultado a la CPU\n",
        "xp2 = xp2_device.copy_to_host()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 512 ms, sys: 62.7 ms, total: 575 ms\n",
            "Wall time: 578 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Y4---i89hH",
        "colab_type": "code",
        "outputId": "36d687a5-5a3a-4f0a-b3c6-00f6ea3257d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "xp2[1:10]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_13FT12yrKQ",
        "colab_type": "text"
      },
      "source": [
        "Veamos, de todo el tiempo total que ha tardado todo el workflow, cuánto ha tardado las funciones en sí."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aAuZGYrxX3x",
        "colab_type": "code",
        "outputId": "f6e524a3-56e8-45de-8065-208be45a3732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%timeit f(x_device, out=xp_device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 loops, best of 3: 27.3 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC2RsemWy1PH",
        "colab_type": "code",
        "outputId": "891f47c1-bab8-468e-c86a-635a4b152755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%timeit fp(xp_device, -1, out=xp2_device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 945.75 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 3: 28.9 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwpON7wQy6Ub",
        "colab_type": "text"
      },
      "source": [
        "Ya puedes intuir que la mayoría del tiempo se ha dedicado al traspaso de datos. Recuerda, esas copias solo son necesarias al comienzo y al final. Podemos concluir que la GPU compensa, generalmente, en las siguientes situaciones:\n",
        "* La proporción y/o la complejidad de las operaciones a realizar es muy grande, hasta el punto que compensa esa copia de memoria.\n",
        "* El tamaño de los arrays es muy grande.\n",
        "* Existe un paralelismo de datos masivo: se puede definir como una función `map`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0IwhXJVRKiT",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Reduce\n",
        "\n",
        "La operación de reducción (`reduce`) es aquella en que dada una colección de elementos (un array), y una función $f$ binaria (de dos argumentos), aplica dicha función para obtener un valor escalar sobre todos los datos. Por ejemplo, si $f(a,b)=a+b$, entonces lo que estaríamos haciendo es simplemente sumar todos los elementos del array. En este caso, como en la operación `map`, estaríamos teniendo un orden de complejidad $O(n)$, con $n$ el número de elementos de entrada.\n",
        "\n",
        "![reduce](https://cdn.kodigoswift.com/wp-content/uploads/2017/07/funcion-reduce.gif)\n",
        "\n",
        "Pero, ¿esta operación se puede paralelizar? A diferencia del `map`, el resultado en una iteración del bucle (el que recorre los elementos) depende de los resultados anteriores: hay que calcular el valor acumulado. En el ejemplo de la suma, el valor resultante de sumar los dos primeros elementos se debe pasar para sumárselo al tercer elemento. Esto tiene pinta que no se puede paralelizar para reducir la complejidad a $O(1)$.\n",
        "\n",
        "Este es un claro ejemplo de que no siempre podemos utilizar el paralelismo para lograr reducir el orden de complejidad de un orden lineal $O(n)$ a uno constante $O(1)$, pero esto no quiere decir que podamos aún conseguir una mejora. El paralelismo se puede aprovechar de otras muchas formas. Pensemos un momento, ¿cómo podríamos paralelizar de alguna forma el cálculo de la suma de elementos de un vector? El siguiente dibujo lo ilustra:\n",
        "\n",
        "![parallelsum](https://github.com/miguelamda/cuda-numba/raw/master/img/parallelsum.png)\n",
        "\n",
        "Curioso, no conseguimos hacer todo el resultado en un solo paso, pero sí que lo podemos conseguir en menos iteraciones que recorriendo elemento a elemento. En concreto, necesitamos un número logarítmico de pasos, por lo que la complejidad se ha reducido de $O(n)$ a $O(log_2 n)$. Aunque no parezca demasiado, piénsalo: si el array de entrada contiene 8 elementos, necesitamos 3 pasos (tampoco mucho), pero si contiene 65536 elementos, tan solo necesitamos 16 pasos! Cuantos más elementos tenga el array de entrada, más notaremos la mejora de hacer el `reduce` en paralelo.\n",
        "\n",
        "Esto ha funcionado porque la suma es una operación binaria conmutativa y asociativa. Otras operaciones que podemos aplicar son: *suma, máximo, mínimo, producto, and lógico, or lógico, etc.*. Operaciones que no podríamos usar serían la resta y la división. En general, el esquema de la reducción en paralelo queda como sigue:\n",
        "\n",
        "![parallelreduce](https://github.com/miguelamda/cuda-numba/raw/master/img/parallelreduce.png)\n",
        "\n",
        "Veamos cómo podemos aplicar un `reduce` en CUDA. Para ello, tenemos que definir nuestra operación binaria asociativa con el decorador `@cuda.reduce`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RTCIt8yz122",
        "colab_type": "code",
        "outputId": "863b78a0-1a89-47f1-de79-c630904d7a51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy\n",
        "from numba import cuda\n",
        "\n",
        "# Definamos la función binaria a usar con la reducción, y se lo indicamos a CUDA\n",
        "@cuda.reduce\n",
        "def sum_reduce(a, b):\n",
        "    return a + b\n",
        "\n",
        "A = (numpy.arange(1234, dtype=numpy.float32)) + 1\n",
        "expect = A.sum()      # Reducción con numpy sum\n",
        "got = sum_reduce(A)   # Reducción con sum en CUDA\n",
        "assert expect == got  # Comprobemos que sale igual\n",
        "print(got)            # Efectivamente, devuelve un escalar"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "761995.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHyFVjyfYHNe",
        "colab_type": "text"
      },
      "source": [
        "Esto es tan solo un pequeño ejemplo, donde quizás incluso la GPU no valga la pena por el tamaño del array que estamos considerando. Veamos otro ejemplo, el reescalado de datos. Aquí debemos recalcular el valor con $x_{new}=\\frac{x-X_{min}}{X_{max}-X_{min}}$. Aquí tenemos que calcular tanto el máximo como el mínimo con reduce, y después con map actualizar los valores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCmzQVz4kjyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Es posible que ahora nos quedemos sin memoria en GPU CUDA_ERROR_OUT_OF_MEMORY,\n",
        "# o incluso sin memoria RAM.\n",
        "# Si es así, reinicia el entorno de ejecución, descomenta las siguientes líneas,\n",
        "# y vuelve a evaluar esta celda ya las siguientes\n",
        "# import numpy as np\n",
        "# n = 500000000\n",
        "# x = np.arange(n).astype(np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dciGJDR1qp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reescalado de datos\n",
        "from numba import vectorize \n",
        "from numba import cuda \n",
        "\n",
        "# Definimos max y min para ser usados con reduce\n",
        "@cuda.reduce\n",
        "def max_reduce(a, b):\n",
        "    return max(a,b)\n",
        "\n",
        "@cuda.reduce\n",
        "def min_reduce(a, b):\n",
        "    return min(a,b)\n",
        "\n",
        "# Definimos la función para normalizar\n",
        "@vectorize(['float32(int32,int32,int32)'], target='cuda')\n",
        "def reescale(x,maxim,minim):\n",
        "    return (x - minim)/(maxim-minim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mL7FJPZYpaC",
        "colab_type": "text"
      },
      "source": [
        "Apliquemos las funciones. Con `reduce`, al menos en Numba hasta hoy, siempre recogemos el valor resultante en la CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3zGjp8B4xgh",
        "colab_type": "code",
        "outputId": "146bdc11-ab9a-488d-bc3f-e7d923dc855c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time \n",
        "# 1. Copiar entrada a la GPU (usamos la misma x de la sección 1.1)\n",
        "d_x = cuda.to_device(x)\n",
        "d_xr = cuda.device_array(shape=d_x.shape, dtype=np.float32)\n",
        "\n",
        "# 2. Lanzamos las funciones reduce para calcular el min y el max\n",
        "xmax = max_reduce(d_x)\n",
        "xmin = min_reduce(d_x)\n",
        "\n",
        "# 4. Aplicamos el map para reescalar los valores, y copiamos el resultado a la vez\n",
        "reescale(d_x,xmax,xmin, out=d_xr)\n",
        "\n",
        "xr = d_xr.copy_to_host()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 619 ms, sys: 787 ms, total: 1.41 s\n",
            "Wall time: 1.41 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA1CEI5U7w6N",
        "colab_type": "code",
        "outputId": "99068ad1-ba79-4ce7-bee1-f4e271cdd439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Veamos una muestra del resultado\n",
        "xr[4000:4010]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8.000e-06, 8.002e-06, 8.004e-06, 8.006e-06, 8.008e-06, 8.010e-06,\n",
              "       8.012e-06, 8.014e-06, 8.016e-06, 8.018e-06], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1afzpbIPZl_8",
        "colab_type": "text"
      },
      "source": [
        "Hagamos una comparativa con Numba sobre CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IIXrtrfkusL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numba import jit\n",
        "\n",
        "@jit(nopython=True)\n",
        "def reescalado(x):\n",
        "    xmin = np.amin(x)\n",
        "    xmax = np.amax(x)\n",
        "    \n",
        "    return (x-xmin)/(xmax-xmin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJlmn4Uvl_P4",
        "colab_type": "code",
        "outputId": "c44df3a1-2254-4dec-9e23-eb6d8ef41c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "xr = reescalado(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.47 s, sys: 2.33 s, total: 3.8 s\n",
            "Wall time: 3.82 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIp9uiBrigZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "98e002a0-c52c-42e4-c39e-20db688ffff7"
      },
      "source": [
        "%%time \n",
        "xmax = x.max()\n",
        "xmin = x.min()\n",
        "\n",
        "xr = (x - xmin)/(xmax-xmin)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.36 s, sys: 2.26 s, total: 4.62 s\n",
            "Wall time: 4.63 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qu9l8B_NPNF",
        "colab_type": "text"
      },
      "source": [
        "# Ejercicio propuesto\n",
        "\n",
        "Supongamos que recibimos una serie de datos en un array y necesitamos normalizarlos; es decir: $x_{new}=\\frac{x-x_{mean}}{x_{stdev}}$. \n",
        "Normalizar dichos datos mediante operaciones map/reduce en CUDA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afR_t6u_kmJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Datos de entrada\n",
        "n=100000000\n",
        "x = np.random.uniform(-3, 3, size=n).astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu_Ot__pbI3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define aquí las funciones de GPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pfHocxmcBLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# Define aquí el workflow de GPU para un mejor manejo de la memoria"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1jLATkFdss8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualiza aquí los primeros 10 valores para ver si ha ido bien"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeJmT7UVfOsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Escribe aquí una función parecida con Numba para CPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkQTwV3dfkc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# Evalúa aquí el rendimiento"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anm5zTa3f1f7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imprime los diez primeros elementos para comprobar si ha ido bien"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}